{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_IMDB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlCUctWZOlbq",
        "outputId": "1611a924-314d-4bad-af8c-ed3c4284fdd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "리뷰의 최대 길이 : 2494\n",
            "리뷰의 평균 길이 : 238.71364\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 최대 단어 개수를 10,000으로 제한하고 훈련 데이터와 테스트 데이터를 받아온다.\n",
        "vocab_size = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)\n",
        "\n",
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터와 이에 대한 레이블이 각각 X_train, y_train에 테스트 데이터와 이에 대한 레이블이 각각 X_test, y_test에 저장되었습니다. IMDB 리뷰 데이터는 이미 정수 인코딩이 된 상태므로 남은 전처리는 패딩뿐입니다. \n",
        "\n",
        "리뷰의 최대 길이와 평균 길이를 확인해보면 리뷰의 최대 길이는 2,494이며 리뷰의 평균 길이는 약 238로 확인된다.\n",
        "\n",
        "평균 길이보다는 조금 크게 데이터를 패딩한다."
      ],
      "metadata": {
        "id": "giS_fQEXQj5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "# 훈련용 리뷰와 테스트용 리뷰의 길이 둘 다 500"
      ],
      "metadata": {
        "id": "x9IeXKulQm44"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 바다나우 어텐션(Bahdanau Attention)\n",
        "\n",
        "어텐션 스코어 함수란 주어진 query와 모든 key에 대해서 유사도를 측정하는 함수를 말한다. ![image.png](data:image/png;base64,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)\n",
        "\n",
        "RNN의 마지막 은닉 상태는 예측을 위해 사용되는데, 몇 가지 유용한 정보들을 손실한 상태이다. 따라서 어텐션 메커니즘을 사용하면사 RNN.이 time step을 지나며 손실했던 정보들을 다시 참고하고자 함."
      ],
      "metadata": {
        "id": "_INRNt6hRFGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "7N9eC6nFRxL_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "U3Ze3uxfRzO4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)"
      ],
      "metadata": {
        "id": "2g_cE26NR2gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "metadata": {
        "id": "5VD3VdgRR48g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설계\n",
        "# 입력층과 임베딩층을 설계\n",
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input) # 10,000개의 단어들을 128차원의 벡터로 임베딩"
      ],
      "metadata": {
        "id": "55uX7f6oR60D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양방향 LSTM 설계\n",
        "# 양방향 LSTM 두 층을 사용하기 위해 첫번째 층 옵션 return_seq = True 설정\n",
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)"
      ],
      "metadata": {
        "id": "yxuIX6wnSAKO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두번째 층\n",
        "# 상태를 리턴받아야 하므로 return_state = True로 설정\n",
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
        "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
      ],
      "metadata": {
        "id": "ix_FzhRWSSEf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 상태의 크기(shape)를 출력\n",
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byfMHVX5SY8_",
        "outputId": "16f348c1-f6c1-427c-959d-c6b978170235"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "순방향 LSTM의 은닉 상태와 셀상태를 forward_h, forward_c에 저장하고, 역방향 LSTM의 은닉 상태와 셀 상태를 backward_h, backward_c에 저장합니다.\n",
        "\n",
        "각 은닉 상태나 셀 상태의 경우에는 128차원을 가지는데, lstm의 경우에는 (500 × 128)의 크기를 가집니다. foward 방향과 backward 방향이 연결된 hidden state벡터가 모든 시점에 대해서 존재함을 의미합니다.\n",
        "\n",
        "**양방향 LSTM을 사용할 경우에는 순방향 LSTM과 역방향 LSTM 각각 은닉 상태와 셀 상태를 가지므로, 양방향 LSTM의 은닉 상태와 셀 상태를 사용하려면 두 방향의 LSTM의 상태들을 연결(concatenate)해주면 됩니다.**\n",
        "\n"
      ],
      "metadata": {
        "id": "VaYJ5X1eSpY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
      ],
      "metadata": {
        "id": "eoLuhgkoSyGH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "어텐션 메커니즘에서는 은닉 상태를 사용합니다. 이를 입력으로 컨텍스트 벡터(context vector)를 얻습니다."
      ],
      "metadata": {
        "id": "aE5J4ynKS0dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h) # 은닉 상태 넘겨줌"
      ],
      "metadata": {
        "id": "axxd2NalS00J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "컨텍스트 벡터를 밀집층(dense layer)에 통과시키고, 이진 분류이므로 최종 출력층에 1개의 뉴런을 배치하고, 활성화 함수로 시그모이드 함수를 사용합니다."
      ],
      "metadata": {
        "id": "BCg_59ZBS272"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "model = Model(inputs=sequence_input, outputs=output)"
      ],
      "metadata": {
        "id": "d_qqn--rS4iC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "옵티마이저로 아담 옵티마이저 사용하고, 모델을 컴파일합니다."
      ],
      "metadata": {
        "id": "4_W7s8n9TJZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6vCW-nVZTJro"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시그모이드 함수를 사용하므로 손실 함수로 binary_crossentropy를 사용하였습니다. 이제 모델을 훈련하겠습니다."
      ],
      "metadata": {
        "id": "o0k4oqEeTL3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9FjWqx2TNCU",
        "outputId": "832b8441-bf6b-4dac-8c20-79d4f5c03fd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "98/98 [==============================] - 701s 7s/step - loss: 0.4722 - accuracy: 0.7698 - val_loss: 0.2908 - val_accuracy: 0.8798\n",
            "Epoch 2/3\n",
            "98/98 [==============================] - 669s 7s/step - loss: 0.2387 - accuracy: 0.9143 - val_loss: 0.2929 - val_accuracy: 0.8815\n",
            "Epoch 3/3\n",
            "98/98 [==============================] - 644s 7s/step - loss: 0.1844 - accuracy: 0.9355 - val_loss: 0.3082 - val_accuracy: 0.8780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "검증 데이터로 테스트 데이터를 사용하여 에포크가 끝날 때마다 테스트 데이터에 대한 정확도를 출력하도록 하였습니다."
      ],
      "metadata": {
        "id": "gRUAKDR_TOzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M77Kx9zTQrw",
        "outputId": "e60c0536-7d0d-41e6-ae32-cde9945e5a18"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 456s 584ms/step - loss: 0.3082 - accuracy: 0.8780\n",
            "\n",
            " 테스트 정확도: 0.8780\n"
          ]
        }
      ]
    }
  ]
}